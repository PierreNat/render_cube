{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train CNN with Synthetic cube\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.empty_cache()\n",
    "print(device)\n",
    "\n",
    "\n",
    "cubes_file = './data/test/cubes.npy'\n",
    "silhouettes_file = './data/test/sils.npy'\n",
    "parameters_file = './data/test/params.npy'\n",
    "\n",
    "target_size = (512, 512)\n",
    "\n",
    "cubes = np.load(cubes_file)\n",
    "sils = np.load(silhouettes_file)\n",
    "params = np.load(parameters_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ratio = 0.9  # 90%training 10%validation\n",
    "split = int(len(cubes)*0.9)\n",
    "test_length = 1000\n",
    "\n",
    "train_im = cubes[:split]  # 90% training\n",
    "train_sil = sils[:split]\n",
    "train_param = params[:split]\n",
    "\n",
    "val_im = cubes[split:]  # remaining ratio for validation\n",
    "val_sil = sils[split:]\n",
    "val_param = params[split:]\n",
    "\n",
    "test_im = cubes[:test_length]\n",
    "test_sil = sils[:test_length]\n",
    "test_param = params[:test_length]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor, Compose\n",
    "\n",
    "class CubeDataset(Dataset):\n",
    "    # write your code\n",
    "    def __init__(self, images, silhouettes, parameters, transform=None):\n",
    "        self.images = images.astype(np.uint8)  # our image\n",
    "        self.silhouettes = silhouettes.astype(np.uint8)  # our related parameter\n",
    "        self.parameters = parameters.astype(np.float16)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Anything could go here, e.g. image loading from file or a different structure\n",
    "        # must return image and center\n",
    "        sel_images = self.images[index]\n",
    "        sel_sils = self.silhouettes[index]\n",
    "        sel_params = self.parameters[index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            sel_images = self.transform(sel_images)\n",
    "            sel_sils = self.transform(sel_sils)\n",
    "\n",
    "        return sel_images, sel_sils, torch.FloatTensor(sel_params)  # return all parameter in tensor form\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)  # return the length of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 32\n",
    "\n",
    "transforms = Compose([ToTensor()])\n",
    "train_dataset = CubeDataset(train_im, train_sil, train_param, transforms)\n",
    "val_dataset = CubeDataset(val_im, val_sil, val_param, transforms)\n",
    "test_dataset = CubeDataset(test_im, test_sil, test_param, transforms)\n",
    "\n",
    "#  Note:\n",
    "#  DataLoader(Dataset,int,bool,int)\n",
    "#  dataset (Dataset) – dataset from which to load the data.\n",
    "#  batch_size (int, optional) – how many samples per batch to load (default: 1)\n",
    "#  shuffle (bool, optional) – set to True to have the data reshuffled at every epoch (default: False).\n",
    "#  num_workers = n - how many threads in background for efficient loading\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of cube images: torch.Size([32, 3, 512, 512]), number of silhouettes: torch.Size([32, 1, 512, 512]), number of parameters: torch.Size([32, 6])\n",
      "image has size: <built-in method size of Tensor object at 0x7f1ec84b51f8>\n",
      "image has size: 786432\n",
      "(512, 512, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAEbZJREFUeJzt3W2MXNV9x/Hvb59tY/ADYByvVYOyRiGoBWQljqialJCKmCjmBUhEUeNElhz1QUoEUmpaqVWkIoW+CCgSSWqVqE6VB0ggwkJpqWWI+oYQ7GATwIA3FYWVUSz8xFqQ3dndf1/Mmc2wZ+29szuzc8f+faTR3HvumZn/2DO/PefOvTOKCMzM6nW1uwAzKx8Hg5llHAxmlnEwmFnGwWBmGQeDmWVaEgySbpH0qqRhSTtb8Rhm1jpq9nEMkrqB14BPASPAc8DnIuLlpj6QmbVMK0YMHwGGI+J/I2Ic+DGwtQWPY2Yt0tOC+1wHvFm3PgJ89Fw3kOTDL81a7+2IuKxIx1YEg2Zpy974knYAO+rWW1CKmdVExP8V7duKYBgB1tetDwJHZ3aKiF3ALvCIwaxsWrGP4TlgSNKVkvqAO4E9LXgcM2uRpo8YImJC0t8CTwLdwPci4qVmP46ZtU7TP66cVxFSeB+DWWtFxIGI2FSkr498NLOMg8HMMg4GM8s4GMws42Aws4yDwcwyDgYzyzgYzCzjYDCzjIPBzDIOBjPLOBjMLONgMLOMg8HMMg4GM8s4GMws42Aws4yDwcwyDgYzyzgYzCzjYDCzjIPBzDIOBjPLOBjMLONgMLOMg8HMMg4GM8s4GMws42Aws4yDwcwyDgYzyzgYzCzjYDCzjIPBzDJzBoOk70k6JunFurZVkvZKOpKuV6Z2SfqWpGFJL0i6oZXFm1lrFBkx/Dtwy4y2ncC+iBgC9qV1gE8DQ+myA/hOc8o0s8U0ZzBExP8AJ2Y0bwV2p+XdwG117d+Pql8CKyStbVaxZrY45ruPYU1EvAWQri9P7euAN+v6jaS2jKQdkvZL2j/PGsysRXqafH+apS1m6xgRu4BdAJJm7WNm7THfEcPvalOEdH0stY8A6+v6DQJH51+embXDfINhD7AtLW8DHq9r/0L6dGIzcLo25TCzzjHnVELSj4BPAJdKGgH+CfgG8Iik7cAbwB2p+8+BLcAw8C7wpRbUbGYtpoj2T+8lhTTb7gkza5aIOBARm4r09ZGPZpZxMJhZxsFgZhkHg5llHAxmlnEwmFnGwWBmGQeDmWWafRKVWdM888wzPPbYYyxdupTu7m4GBgaoHQjX09PDQg+KiwgmJiaICCqVCuPj49xxxx1ce+21zSi/o/nIRyudBx98kIMHD7Jq1SpWrlxJT08PXV1d7wuDmdeNqr3u668nJiYYHx9ndHSUe++9twnPpFx85KN1tGeeeYbly5ezbNkyent76evro6+vj+7u7ulLV1fX9PV8LvX3Ubv09fXR39/P8uXLufvuu9v9z9BWnkpYqWzcuJElS5YwMDDAkiVL6Ovro6urC0kLnjrMVH9/koiI6VHJypUrm/pYncbBYKVy9dVX09XVRW9v7/sCYTGmmpLo6uoiIujt7W3545WZpxJWGkNDQwB0d3fPKxDq+88cDRS9n1rf7u7uBio//zgYrDQ2btxIRBAR9Pf3NxQOM4NgZtts62e7HweDg8FKqDaM7+oq9vI81xt+PlOQ2m2uv/76hm97vnAwWKnUdgLWlouY+dHjzPb65UaC4kLez+Cdj1YKtf0LV1xxRUO3m20KUWTbXPfpqYRZiSxZsqRw3yJv9tkO4FusTzk6mYPBSqXIX+qZb+xzHb071/4HB8TsHAxWCrX5/OTk5Fn7nO1NPLO99slG7TIXh0POwWCl8OEPfxiAU6dOnbPfXG/i+h2RZ9spaXPzzkcrlePHj3PJJZc0fLv6N//evXuZnJxkcnKS/v5+br75ZiLCI4MGOBisFH7/+9835X4OHTrENddcQ6VS4fTp0xw/fpyTJ09e8Oc+NMrBYKUwNTVFX18f4+Pj5+x3tr/8teMfBgcHWbZsGRMTE3R1dXHmzBlOnDjhYGiQ9zFYaXzgAx+Ys89c04H607Rr3+OwatWqZpV4wXAwWGmsWbNmwfdx8cUX89577zE6Osro6ChjY2PnHC14x+TsPJWw0rjooosWdPvadGLZsmUsXbqU1atXc/XVV09vO9ttLOdgsNJ4++23F3wfC/3KN6vyVMJK4+WXXz7n9qIHLDXK04mcg8FKo1KpFJpOzAyIuQLjbNtaFTTnAweDlcrll19euG/9m7rR72SYKxAu9MBwMFgp1L6UpdHTnRs9orHIKCEimJqaaqiO882cwSBpvaSnJR2W9JKkr6T2VZL2SjqSrlemdkn6lqRhSS9IuqHVT8I6Xy0Yip41We9C/+veCkVGDBPA3RHxIWAz8DeSrgF2AvsiYgjYl9YBPg0MpcsO4DtNr9rOO319fUD10OjaX+tm/tVuJDxqfbdv3960x+80cwZDRLwVEb9Oy6PAYWAdsBXYnbrtBm5Ly1uB70fVL4EVktY2vXI7r9QOhR4ZGSEiGBsba+jU6bnUf2XcudQ/5pe//OUFP26namgfg6QNwPXAs8CaiHgLquEB1PYarQPerLvZSGozO6tXXnkFyL+nsZHpxFyXRu6nUqk0/iTOI4UPcJJ0EfAo8NWIeOccO3xm25D9r0jaQXWqYTY9bZA0/QOzU1NT72sv+q3R81ELhKmpKSYnJy/4YCj0Ly2pl2oo/CAiHkvNv6tNEdL1sdQ+Aqyvu/kgcHTmfUbErojYVPRHNu3CUguHyclJpqampt+0zZxezDaqmJycnP5x2wtZkU8lBDwEHI6Ib9Zt2gNsS8vbgMfr2r+QPp3YDJyuTTnMiqhUKlQqFcbGxqhUKtNfulJ/qY0mFnqZeb/j4+PTJ2FdyIpMJW4E/hL4jaSDqe3vgW8Aj0jaDrwB3JG2/RzYAgwD7wJfamrFdl46cuQIGzduZGpqirGxMc6cOTM9pK/90nXtB2cBenqqL935nBNRP9qYmJiYHi3UQuHMmTN8+9vfbs4T61Aqw2fAksInvditt94KwMDAwPR3KtQuUA2DmT8Cs5DXb+01V5uyALz77rt88Ytf5OMf//i877esIuJA0am7g8FKY2hoiI0bN07/4Evtx22B6V+h7u7uzo52nM9ruPbxZe22tZ2cjz76aBOeSTk5GKyj1UYORfX29rJy5Ur6+/uJCEZHR3nnnXeIiOlfuKpUKoyOjnL8+PH33fa1117jyJEjTau9zBwMZpZpJBh8EpWZZRwMZpZxMJhZxsFgZhkHg5llHAxmlnEwmFnGwWBmGQeDmWUcDGaWcTCYWcbBYGYZB4OZZRwMZpZxMJhZxsFgZhkHg5llHAxmlnEwmFnGwWBmGQeDmWUcDGaWcTCYWcbBYGYZB4OZZRwMZpZxMJhZxsFgZhkHg5llHAxmlnEwmFlmzmCQNCDpV5IOSXpJ0tdT+5WSnpV0RNLDkvpSe39aH07bN7T2KZhZsxUZMYwBN0XEnwDXAbdI2gzcB9wfEUPASWB76r8dOBkRHwTuT/3MrIPMGQxRdSat9qZLADcBP03tu4Hb0vLWtE7a/klJalrFZtZyhfYxSOqWdBA4BuwFfgucioiJ1GUEWJeW1wFvAqTtp4HVs9znDkn7Je1f2FMws2YrFAwRMRkR1wGDwEeAD83WLV3PNjqIrCFiV0RsiohNRYs1s8XR0KcSEXEK+AWwGVghqSdtGgSOpuURYD1A2n4JcKIZxZrZ4ijyqcRlklak5SXAzcBh4Gng9tRtG/B4Wt6T1knbn4qIbMRgZuXVM3cX1gK7JXVTDZJHIuIJSS8DP5b0z8DzwEOp/0PAf0gapjpSuLMFdZtZC6kMf8wlhT+4MGutiDhQdJ+ej3w0s4yDwcwyDgYzyzgYzCzjYDCzjIPBzDIOBjPLOBjMLONgMLOMg8HMMg4GM8s4GMws42Aws4yDwcwyDgYzyzgYzCzjYDCzjIPBzDIOBjPLOBjMLONgMLOMg8HMMg4GM8s4GMws42Aws4yDwcwyDgYzyzgYzCzjYDCzjIPBzDIOBjPLOBjMLONgMLNM4WCQ1C3peUlPpPUrJT0r6YikhyX1pfb+tD6ctm9oTelm1iqNjBi+AhyuW78PuD8ihoCTwPbUvh04GREfBO5P/cysgxQKBkmDwK3Av6V1ATcBP01ddgO3peWtaZ20/ZOpv5l1iKIjhgeArwFTaX01cCoiJtL6CLAuLa8D3gRI20+n/u8jaYek/ZL2z7N2M2uROYNB0meAYxFxoL55lq5RYNsfGiJ2RcSmiNhUqFIzWzQ9BfrcCHxW0hZgALiY6ghihaSeNCoYBI6m/iPAemBEUg9wCXCi6ZWbWcvMOWKIiHsiYjAiNgB3Ak9FxOeBp4HbU7dtwONpeU9aJ21/KiKyEYOZlddCjmP4O+AuScNU9yE8lNofAlan9ruAnQsr0cwWm8rwx1xS+IMLs9aKiANF9+n5yEczyzgYzCzjYDCzjIPBzDIOBjPLOBjMLONgMLOMg8HMMg4GM8s4GMws42Aws4yDwcwyDgYzyzgYzCzjYDCzjIPBzDIOBjPLOBjMLONgMLOMg8HMMg4GM8s4GMws42Aws4yDwcwyDgYzyzgYzCzjYDCzjIPBzDIOBjPLOBjMLONgMLOMg8HMMg4GM8s4GMwsUygYJL0u6TeSDkran9pWSdor6Ui6XpnaJelbkoYlvSDphlY+ATNrvkZGDH8eEddFxKa0vhPYFxFDwL60DvBpYChddgDfaVaxZrY4FjKV2ArsTsu7gdvq2r8fVb8EVkhau4DHMbNFVjQYAvhvSQck7UhtayLiLYB0fXlqXwe8WXfbkdT2PpJ2SNpfm5qYWXn0FOx3Y0QclXQ5sFfSK+foq1naImuI2AXsApCUbTez9ik0YoiIo+n6GPAz4CPA72pThHR9LHUfAdbX3XwQONqsgs2s9eYMBknLJC2vLQN/AbwI7AG2pW7bgMfT8h7gC+nTic3A6dqUw8w6Q5GpxBrgZ5Jq/X8YEf8l6TngEUnbgTeAO1L/nwNbgGHgXeBLTa/azFpKEe2f3ksaBV5tdx0FXQq83e4iCuiUOqFzau2UOmH2Wv8oIi4rcuOiOx9b7dW64yNKTdL+Tqi1U+qEzqm1U+qEhdfqQ6LNLONgMLNMWYJhV7sLaECn1NopdULn1NopdcICay3FzkczK5eyjBjMrETaHgySbpH0ajpNe+fct2hpLd+TdEzSi3VtpTy9XNJ6SU9LOizpJUlfKWO9kgYk/UrSoVTn11P7lZKeTXU+LKkvtfen9eG0fcNi1FlXb7ek5yU9UfI6W/tVCBHRtgvQDfwWuAroAw4B17Sxnj8DbgBerGv7F2BnWt4J3JeWtwD/SfXckM3As4tc61rghrS8HHgNuKZs9abHuygt9wLPpsd/BLgztX8X+Ku0/NfAd9PyncDDi/zvehfwQ+CJtF7WOl8HLp3R1rT/+0V7Imd5ch8Dnqxbvwe4p801bZgRDK8Ca9PyWqrHXAD8K/C52fq1qe7HgU+VuV5gKfBr4KNUD77pmfk6AJ4EPpaWe1I/LVJ9g1S/W+Qm4In0RipdnekxZwuGpv3ft3sqUegU7TZb0OnliyENY6+n+te4dPWm4flBqifa7aU6SjwVEROz1DJdZ9p+Gli9GHUCDwBfA6bS+uqS1gkt+CqEeu0+8rHQKdolVYraJV0EPAp8NSLeSee0zNp1lrZFqTciJoHrJK2genbuh85RS1vqlPQZ4FhEHJD0iQK1tPv/v+lfhVCv3SOGTjhFu7Snl0vqpRoKP4iIx1JzaeuNiFPAL6jOc1dIqv1hqq9lus60/RLgxCKUdyPwWUmvAz+mOp14oIR1Aq3/KoR2B8NzwFDa89tHdSfOnjbXNFMpTy9XdWjwEHA4Ir5Z1nolXZZGCkhaAtwMHAaeBm4/S521+m8Hnoo0MW6liLgnIgYjYgPV1+FTEfH5stUJi/RVCIu58+ksO1G2UN2j/lvgH9pcy4+At4AK1ZTdTnXeuA84kq5Xpb4CHkx1/wbYtMi1/inV4eALwMF02VK2eoE/Bp5Pdb4I/GNqvwr4FdXT838C9Kf2gbQ+nLZf1YbXwSf4w6cSpasz1XQoXV6qvW+a+X/vIx/NLNPuqYSZlZCDwcwyDgYzyzgYzCzjYDCzjIPBzDIOBjPLOBjMLPP/Z5I/5NoHwgwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#  try to iterate over the train dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for image, silhouette, parameters in train_dataloader:\n",
    "    print('number of cube images: {}, number of silhouettes: {}, number of parameters: {}'.format(image.size(), silhouette.size(), parameters.size()))\n",
    "\n",
    "    im = 2\n",
    "    image2show = image[im]  # indexing random  one image\n",
    "    sil2show = silhouette[im]\n",
    "    parm = parameters[im] \n",
    "\n",
    "    print('image has size: {}'.format(image2show.size))\n",
    "    \n",
    "    # tensor to numpy:\n",
    "    image2shownp = image2show.numpy()\n",
    "#     .reshape((512, 512,3))  # reshape the torch format to numpy\n",
    "    print('image has size: {}'.format(image2shownp.size))\n",
    "    \n",
    "    image2shownp = np.transpose(image2shownp, (2, 1, 0))\n",
    "    print(image2shownp.shape)\n",
    "    plt.imshow(image2shownp)\n",
    "    print\n",
    "\n",
    "    break  # break here just to show 1 batch of data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
