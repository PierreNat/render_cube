{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train CNN with Synthetic cube\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.empty_cache()\n",
    "print(device)\n",
    "\n",
    "\n",
    "cubes_file = './data/test/cubes.npy'\n",
    "silhouettes_file = './data/test/sils.npy'\n",
    "parameters_file = './data/test/params.npy'\n",
    "\n",
    "target_size = (512, 512)\n",
    "\n",
    "cubes = np.load(cubes_file)\n",
    "sils = np.load(silhouettes_file)\n",
    "params = np.load(parameters_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ratio = 0.9  # 90%training 10%validation\n",
    "split = int(len(cubes)*0.9)\n",
    "test_length = 1000\n",
    "\n",
    "train_im = cubes[:split]  # 90% training\n",
    "train_sil = sils[:split]\n",
    "train_param = params[:split]\n",
    "\n",
    "val_im = cubes[split:]  # remaining ratio for validation\n",
    "val_sil = sils[split:]\n",
    "val_param = params[split:]\n",
    "\n",
    "test_im = cubes[:test_length]\n",
    "test_sil = sils[:test_length]\n",
    "test_param = params[:test_length]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor, Compose\n",
    "\n",
    "class CubeDataset(Dataset):\n",
    "    # write your code\n",
    "    def __init__(self, images, silhouettes, parameters, transform=None):\n",
    "        self.images = images.astype(np.uint8)  # our image\n",
    "        self.silhouettes = silhouettes.astype(np.uint8)  # our related parameter\n",
    "        self.parameters = parameters.astype(np.float16)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Anything could go here, e.g. image loading from file or a different structure\n",
    "        # must return image and center\n",
    "        sel_images = self.images[index]\n",
    "        sel_sils = self.silhouettes[index]\n",
    "        sel_params = self.parameters[index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            sel_images = self.transform(sel_images)\n",
    "            sel_sils = self.transform(sel_sils)\n",
    "\n",
    "        return sel_images, sel_sils, torch.FloatTensor(sel_params)  # return all parameter in tensor form\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)  # return the length of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 32\n",
    "\n",
    "transforms = Compose([ToTensor()])\n",
    "train_dataset = CubeDataset(train_im, train_sil, train_param, transforms)\n",
    "val_dataset = CubeDataset(val_im, val_sil, val_param, transforms)\n",
    "test_dataset = CubeDataset(test_im, test_sil, test_param, transforms)\n",
    "\n",
    "#  Note:\n",
    "#  DataLoader(Dataset,int,bool,int)\n",
    "#  dataset (Dataset) – dataset from which to load the data.\n",
    "#  batch_size (int, optional) – how many samples per batch to load (default: 1)\n",
    "#  shuffle (bool, optional) – set to True to have the data reshuffled at every epoch (default: False).\n",
    "#  num_workers = n - how many threads in background for efficient loading\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-46b528a3bae7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilhouette\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'number of cube images: {}, number of silhouettes: {}, number of parameters: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilhouette\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#  try to iterate over the train dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for image, silhouette, parameters in train_dataloader:\n",
    "    print('number of cube images: {}, number of silhouettes: {}, number of parameters: {}'.format(image.size(), silhouette.size(), parameters.size()))\n",
    "\n",
    "    im = 2\n",
    "    image2show = image[im]  # indexing random  one image\n",
    "    sil2show = silhouette[im]\n",
    "    parm = parameters[im] \n",
    "\n",
    "    print('image has size: {}'.format(image2show.size))\n",
    "    \n",
    "    # tensor to numpy:\n",
    "    image2shownp = image2show.numpy()\n",
    "#     .reshape((512, 512,3))  # reshape the torch format to numpy\n",
    "    print('image has size: {}'.format(image2shownp.size))\n",
    "    \n",
    "    image2shownp = np.transpose(image2shownp, (2, 1, 0))\n",
    "    print(image2shownp.shape)\n",
    "    plt.imshow(image2shownp)\n",
    "    print\n",
    "\n",
    "    break  # break here just to show 1 batch of data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
